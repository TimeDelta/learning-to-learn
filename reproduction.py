import math
import random
from collections import defaultdict
from warnings import warn

import numpy as np
import torch
from neat.config import *
from neat.reproduction import DefaultReproduction


class GuidedReproduction(DefaultReproduction):
    """
    Standard NEAT reproduction except half of the children for each species are generated by guided evolution.
    """

    @classmethod
    def parse_config(cls, param_dict):
        return DefaultClassConfig(
            param_dict,
            [
                ConfigParameter("elitism", int, 5),
                ConfigParameter("survival_threshold", float, 0.2),
                ConfigParameter("min_species_size", int, 1),
                ConfigParameter("kl_partial_slice_ratio", float, 1.0),
                ConfigParameter("kl_partial_slice_dims", int, -1),
                ConfigParameter("kl_partial_slice_start", int, 0),
            ],
        )

    def __init__(self, config, reporters, stagnation):
        super().__init__(config, reporters, stagnation)
        self.guide_fn = None
        self.guided_start_generation = getattr(config, "guided_start_generation", 0)
        self.guided_max_fraction = float(getattr(config, "guided_max_fraction", 0.5))
        self.guided_ramp_generations = max(1, int(getattr(config, "guided_ramp_generations", 20)))
        self.optimizer_validator = None
        self.optimizer_validation_retries = getattr(config, "optimizer_validation_retries", 3)

    def _is_optimizer_valid(self, optimizer) -> bool:
        validator = getattr(self, "optimizer_validator", None)
        if not callable(validator):
            return True
        try:
            return bool(validator(optimizer))
        except Exception as exc:
            warn(f"Optimizer validator raised {exc}; treating optimizer as invalid")
            return False

    def _guided_fraction(self, generation: int) -> float:
        if generation < self.guided_start_generation:
            return 0.0
        steps_since_start = generation - self.guided_start_generation + 1
        ramp_progress = min(1.0, max(0.0, steps_since_start / self.guided_ramp_generations))
        return self.guided_max_fraction * ramp_progress

    def reproduce(self, config, species, pop_size, generation, task):
        # Filter out stagnated species, collect the set of non-stagnated
        # species members, and compute their average adjusted fitness.
        # The average adjusted fitness scheme (normalized to the interval
        # [0, 1]) allows the use of negative fitness values without
        # interfering with the shared fitness scheme.
        all_fitnesses = []
        remaining_species = []
        for stagnant_sid, stagnant_species, stagnant in self.stagnation.update(species, generation):
            if stagnant:
                self.reporters.species_stagnant(stagnant_sid, stagnant_species)
            else:
                all_fitnesses.extend(m.fitness for m in stagnant_species.members.values())
                remaining_species.append(stagnant_species)
        # Ensure the species set drops stagnated species but preserves survivors for history.
        species.species = {s.key: s for s in remaining_species}
        # The above comment was not quite what was happening - now getting fitnesses
        # only from members of non-stagnated species.

        # No species left.
        if not remaining_species:
            return {}

        # Find minimum/maximum fitness across the entire population, for use in
        # species adjusted fitness computation.
        min_fitness = min(all_fitnesses)
        max_fitness = max(all_fitnesses)
        # Do not allow the fitness range to be zero, as we divide by it below.
        # TODO: The ``1.0`` below is rather arbitrary, and should be configurable.
        fitness_range = max(1.0, max_fitness - min_fitness)
        for species in remaining_species:
            # Compute adjusted fitness.
            msf = np.mean([m.fitness for m in species.members.values()], axis=0)
            species.adjusted_fitness = (msf - min_fitness) / fitness_range

        self._log_species_metrics(remaining_species)

        adjusted_fitnesses = [s.adjusted_fitness for s in remaining_species]
        avg_adjusted_fitness = np.mean(adjusted_fitnesses, axis=0)  # type: float
        self.reporters.info("Average adjusted fitness: {:.3f}".format(avg_adjusted_fitness))

        # Compute the number of new members for each species in the new generation.
        previous_sizes = [len(s.members) for s in remaining_species]
        # Isn't the effective min_species_size going to be max(min_species_size,
        # self.reproduction_config.elitism)? That would probably produce more accurate tracking
        # of population sizes and relative fitnesses... doing. TODO: document.
        min_species_size = max(self.reproduction_config.min_species_size, self.reproduction_config.elitism)
        spawn_amounts = self.compute_spawn(adjusted_fitnesses, previous_sizes, pop_size, min_species_size)

        new_population = {}
        for spawn, s in zip(spawn_amounts, remaining_species):
            spawn = max(spawn, self.reproduction_config.elitism)
            old_members = sorted(s.members.items(), key=lambda item: item[1].fitness, reverse=True)
            # elites
            for gid, g in old_members[: self.reproduction_config.elitism]:
                new_population[gid] = g
            remaining_spawn = spawn - self.reproduction_config.elitism
            if remaining_spawn <= 0:
                continue

            # 1) guided children
            guided_fraction = self._guided_fraction(generation)
            guided_quota = int(round(remaining_spawn * guided_fraction))
            if guided_quota == 0 and guided_fraction > 0.0 and remaining_spawn > 0:
                guided_quota = 1
            guided_quota = min(guided_quota, remaining_spawn)
            guided_children = []
            if guided_quota > 0 and self.guide_fn is not None and generation >= self.guided_start_generation:
                guided_children = self.guide_fn(list(s.members.values()), self.reproduction_config, guided_quota)

            for kid in guided_children:
                existing_key = getattr(kid, "key", None)
                gid = (
                    existing_key
                    if existing_key is not None and existing_key not in new_population
                    else next(self.genome_indexer)
                )
                kid.key = gid
                new_population[gid] = kid
                self.ancestors[gid] = (None, None)
            remaining_spawn -= len(guided_children)
            if remaining_spawn <= 0:
                continue

            # 2) standard NEAT crossover + mutation
            if remaining_spawn > 0:
                repro_cutoff = max(2, int(math.ceil(self.reproduction_config.survival_threshold * len(old_members))))
                parents = old_members[:repro_cutoff]
                for _ in range(remaining_spawn):
                    attempts = 0
                    child_added = False
                    while attempts < max(1, self.optimizer_validation_retries):
                        attempts += 1
                        p1_id, p1 = random.choice(parents)
                        p2_id, p2 = random.choice(parents)
                        cid = next(self.genome_indexer)
                        child = config.genome_type(cid)
                        child.configure_crossover(p1, p2, config.genome_config)
                        child.mutate(config.genome_config)
                        optimizer_valid = True
                        if hasattr(child, "compile_optimizer"):
                            child.compile_optimizer(config.genome_config)
                            graph_dict = getattr(child, "graph_dict", None)
                            if graph_dict:
                                edge_index = graph_dict.get("edge_index")
                                num_edges = 0
                                if edge_index is not None:
                                    if isinstance(edge_index, torch.Tensor):
                                        edge_tensor = edge_index
                                    else:
                                        edge_tensor = torch.as_tensor(edge_index)
                                    if edge_tensor.dim() == 1:
                                        num_edges = edge_tensor.numel() // 2
                                    elif edge_tensor.dim() == 2:
                                        num_edges = edge_tensor.size(1)
                                if num_edges == 0:
                                    warn(
                                        "NEAT offspring produced an empty graph after mutation; consider adjusting mutation rates."
                                    )
                            optimizer = getattr(child, "optimizer", None)
                            if not self._is_optimizer_valid(optimizer):
                                optimizer_valid = False
                                warn("NEAT offspring optimizer failed parameter-update check; retrying mutation.")
                        if not optimizer_valid:
                            continue
                        new_population[cid] = child
                        self.ancestors[cid] = (p1_id, p2_id)
                        child_added = True
                        break
                    if not child_added:
                        fallback_child = self._build_random_minimum_genome(config, cid)
                        optimizer = None
                        if hasattr(fallback_child, "compile_optimizer"):
                            try:
                                fallback_child.compile_optimizer(config.genome_config)
                                optimizer = getattr(fallback_child, "optimizer", None)
                            except Exception as exc:
                                self.reporters.info(
                                    f"Fallback minimum graph for species {s.key} failed to compile cleanly: {exc}"
                                )
                        if optimizer is not None and not self._is_optimizer_valid(optimizer):
                            self.reporters.info(
                                f"Fallback optimizer for species {s.key} failed validation; proceeding to keep minimum graph child."
                            )
                        new_population[cid] = fallback_child
                        self.ancestors[cid] = (p1_id, p2_id)
                        self.reporters.info(
                            f"Inserted fallback minimum graph for species {s.key} after {attempts} unsuccessful attempts."
                        )

        return new_population

    def _build_random_minimum_genome(self, config, key):
        genome = config.genome_type(key)
        if not hasattr(genome, "connections") or genome.connections is None:
            genome.connections = {}
        if not hasattr(genome, "nodes") or genome.nodes is None:
            genome.nodes = {}

        try:
            genome.configure_new(config.genome_config)
        except Exception:
            if hasattr(genome, "create_node"):
                for node_key in getattr(config.genome_config, "output_keys", []):
                    try:
                        genome.nodes[node_key] = genome.create_node(config.genome_config, node_key)
                    except Exception:
                        continue

        input_keys = list(getattr(config.genome_config, "input_keys", []))
        output_keys = list(getattr(config.genome_config, "output_keys", []))
        rng = random.Random()
        hidden_target = max(2, len(output_keys) or 1)
        jitter = rng.randint(0, max(1, len(input_keys)))
        required_hidden = max(2, min(hidden_target + jitter, hidden_target + 3))

        def reserve_node_id():
            next_id = getattr(genome, "next_node_id", None)
            if isinstance(next_id, int):
                candidate = next_id
                genome.next_node_id = next_id + 1
            else:
                candidate = max([k for k in genome.nodes.keys() if isinstance(k, int)] or [-1]) + 1
            while candidate in genome.nodes:
                candidate += 1
            if hasattr(genome, "next_node_id") and genome.next_node_id <= candidate:
                genome.next_node_id = candidate + 1
            return candidate

        def ensure_connection(src, dst):
            key = (src, dst)
            conn = genome.connections.get(key)
            if conn is not None:
                conn.enabled = True
                return conn
            connection = None
            if hasattr(genome, "create_connection"):
                try:
                    connection = genome.create_connection(config.genome_config, src, dst)
                except Exception:
                    connection = None
            if connection is None:
                connection = type("FallbackConnection", (), {})()
                connection.key = key
                connection.enabled = True
            genome.connections[key] = connection
            return connection

        hidden_ids = []
        while len(hidden_ids) < required_hidden:
            hid = reserve_node_id()
            node = genome.create_node(config.genome_config, hid)
            if hasattr(node, "node_type") and not node.node_type:
                node.node_type = "hidden"
            genome.nodes[hid] = node
            hidden_ids.append(hid)

        if not output_keys:
            setattr(genome, "_minimum_graph_fallback", True)
            return genome

        shuffled_inputs = input_keys[:]
        rng.shuffle(shuffled_inputs)
        shuffled_hiddens = hidden_ids[:]
        rng.shuffle(shuffled_hiddens)

        if input_keys:
            for hid_idx, hid in enumerate(shuffled_hiddens):
                src = shuffled_inputs[hid_idx % len(shuffled_inputs)]
                ensure_connection(src, hid)
            for input_key in shuffled_inputs:
                dst = rng.choice(hidden_ids)
                ensure_connection(input_key, dst)
        else:
            for idx, hid in enumerate(hidden_ids[1:], start=1):
                ensure_connection(hidden_ids[idx - 1], hid)

        shuffled_outputs = output_keys[:]
        rng.shuffle(shuffled_outputs)
        hidden_cycle = hidden_ids[:]
        rng.shuffle(hidden_cycle)
        for idx, out_key in enumerate(shuffled_outputs):
            src = hidden_cycle[idx % len(hidden_cycle)]
            ensure_connection(src, out_key)

        extra_edges = rng.randint(0, len(hidden_ids))
        for _ in range(extra_edges):
            src = rng.choice(hidden_ids)
            dst_pool = hidden_ids + output_keys
            if not dst_pool:
                break
            dst = rng.choice(dst_pool)
            if src == dst:
                continue
            ensure_connection(src, dst)

        for hid in hidden_ids:
            has_in = any(conn_key[1] == hid for conn_key in genome.connections.keys())
            if not has_in and input_keys:
                ensure_connection(shuffled_inputs[0], hid)
            has_out = any(conn_key[0] == hid for conn_key in genome.connections.keys())
            if not has_out and output_keys:
                ensure_connection(hid, output_keys[0])

        for out_key in output_keys:
            has_incoming = any(conn_key[1] == out_key for conn_key in genome.connections.keys())
            if not has_incoming:
                ensure_connection(hidden_ids[0], out_key)

        setattr(genome, "_minimum_graph_fallback", True)
        setattr(genome, "hidden_node_ids", list(hidden_ids))
        return genome

    def _log_species_metrics(self, species_list):
        for species in species_list:
            metric_values = defaultdict(list)
            members_with_metrics = 0
            for member in species.members.values():
                metrics = getattr(member, "fitnesses", None)
                if not metrics:
                    continue
                members_with_metrics += 1
                for metric, value in metrics.items():
                    metric_name = self._metric_name(metric)
                    metric_values[metric_name].append(value)

            total_members = len(species.members)
            if not metric_values:
                self.reporters.info(
                    f"Species {species.key}: no per-metric fitness data available ({members_with_metrics}/{total_members} members)"
                )
                continue

            parts = []
            for metric_name in sorted(metric_values.keys()):
                values = metric_values[metric_name]
                mean_value = sum(values) / len(values)
                parts.append(f"{metric_name}: {mean_value:.4f}")
            joined = ", ".join(parts)
            self.reporters.info(
                f"Species {species.key} mean fitness metrics ({members_with_metrics}/{total_members} members contributing): {joined}"
            )

    @staticmethod
    def _metric_name(metric):
        if hasattr(metric, "name"):
            return getattr(metric, "name")
        if hasattr(metric, "__name__"):
            return getattr(metric, "__name__")
        return str(metric)
