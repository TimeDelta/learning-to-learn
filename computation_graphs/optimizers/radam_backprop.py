# Generated by ChatGPT
import torch
import torch.nn as nn
from torch.nn.parameter import Parameter
from typing import Dict, List, Tuple

class RAdamBackprop(nn.Module):
    moment1: Dict[str, torch.Tensor] = torch.jit.Attribute({}, Dict[str, torch.Tensor])
    moment2: Dict[str, torch.Tensor] = torch.jit.Attribute({}, Dict[str, torch.Tensor])

    def __init__(self, step_size: float = 0.001, beta1: float = 0.9, beta2: float = 0.999, eps: float = 1e-8):
        super(RAdamBackprop, self).__init__()
        self.step_size = step_size
        self.beta1 = beta1
        self.beta2 = beta2
        self.eps = eps
        self.step = 0
        self.moment1: Dict[str, torch.Tensor] = {}
        self.moment2: Dict[str, torch.Tensor] = {}

    def forward(self, loss: torch.Tensor, prev_loss: torch.Tensor,
                named_parameters: List[Tuple[str, Parameter]]) -> Dict[str, torch.Tensor]:
        self.step += 1
        rho_inf = 2.0 / (1.0 - self.beta2) - 1.0
        params = [param for _, param in named_parameters]
        grads = torch.autograd.grad([loss], params, create_graph=False)
        new_params: Dict[str, torch.Tensor] = {}
        for (name, param), grad in zip(named_parameters, grads):
            if grad is None:
                grad = torch.zeros_like(param)
            if name not in self.moment1:
                self.moment1[name] = torch.zeros_like(param)
                self.moment2[name] = torch.zeros_like(param)
            m = self.moment1[name]
            v = self.moment2[name]
            # Update Adam moments
            m = self.beta1 * m + (1 - self.beta1) * grad
            v = self.beta2 * v + (1 - self.beta2) * (grad * grad)
            # Bias-corrected moments
            m_hat = m / (1 - self.beta1 ** self.step)
            v_hat = v / (1 - self.beta2 ** self.step)
            # Compute rho_t for rectification
            beta2_t = self.beta2 ** self.step
            rho_t = rho_inf - 2 * self.step * beta2_t / (1 - beta2_t)
            if rho_t > 4:
                # Compute rectification term r
                r = torch.sqrt(((rho_t - 4) * (rho_t - 2) * rho_inf) /
                               ((rho_inf - 4) * (rho_inf - 2) * rho_t))
                # RAdam update
                new_params[name] = param - self.step_size * r * (m_hat / (torch.sqrt(v_hat) + self.eps))
            else:
                # Fall back to Adam-like update
                new_params[name] = param - self.step_size * m_hat
            self.moment1[name] = m
            self.moment2[name] = v
        return new_params

if __name__ == "__main__":
    optimizer = torch.jit.script(RAdamBackprop())
    torch.jit.save(optimizer, __file__.replace('.py', '.pt'))
    print(optimizer.graph)
